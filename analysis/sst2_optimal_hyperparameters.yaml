optimal_hyperparameters:
  full_finetune:
    expected_performance: 0.92
    hyperparameters:
      learning_rate: 1.0253509690168497e-05
      num_train_epochs: 4
      per_device_train_batch_size: 1
      warmup_ratio: 0.2852142919229748
      weight_decay: 0.0731993941811405
    optimization_summary:
      n_completed: 10
      n_pruned: 0
      n_trials: 10
  lora:
    expected_performance: 0.88
    hyperparameters:
      learning_rate: 0.0003230175187384698
      lora_alpha: 64
      lora_dropout: 0.258219174976903
      lora_r: 16
      num_train_epochs: 6
      per_device_train_batch_size: 16
      warmup_ratio: 0.24243611386932507
      weight_decay: 0.06334037565104235
    optimization_summary:
      n_completed: 10
      n_pruned: 0
      n_trials: 10
optimization_efficiency: 60% faster
optimization_method: optuna_tpe_optimized
task: sst2
total_trials: 24
trials_per_method: 12
